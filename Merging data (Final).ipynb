{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show all columns and rows data\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "sourcedir = Path(r\"\"\"lucas\\Desktop\\python_data\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#BPI sarm cell/slot offline & online history\n",
    "bpi_sarm = pd.read_csv('Desktop/python_data/bpi_sarm3.csv', parse_dates=True, low_memory=False, dtype=str)\n",
    "bpi_sarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpi_sarm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRB sarm cell/slot offline & online history\n",
    "prb_sarm = pd.read_csv('Desktop/python_data/prb_sarm3.csv', parse_dates=True, low_memory=False, dtype=str)\n",
    "prb_sarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prb_sarm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BPI redshift cell/slot test history\n",
    "bpi_redshift = pd.read_csv('Desktop/python_data/bpi_redshift3.csv', parse_dates=True, low_memory=False, dtype=str)\n",
    "bpi_redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpi_redshift.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRB redshift cell/slot test history\n",
    "prb_redshift = pd.read_csv('Desktop/python_data/prb_redshift3.csv', parse_dates=True, low_memory=False, dtype=str)\n",
    "prb_redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prb_redshift.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate SARM data for same structure parameter\n",
    "offline_history = pd.concat([bpi_sarm, prb_sarm], ignore_index=True, sort=False)\n",
    "offline_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Redshift data for same structure parameter\n",
    "cell_history = pd.concat([bpi_redshift, prb_redshift], ignore_index=True, sort=False)\n",
    "cell_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge data : offline_history + cell_history\n",
    "result = pd.merge(offline_history, \n",
    "                  cell_history, \n",
    "                  how='left', \n",
    "                  left_on=['tester_id', 'col_id', 'row_id'], \n",
    "                  right_on=['tester_id', 'col_id', 'row_id'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save result with header to result3.csv to the result directory\n",
    "result.to_csv('Desktop/python_data/result3.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format every row of offline_timestamp,online_timestamp, and end_date_time columns into \n",
    "# %Y - Year full version : 2020, %m - Month as a number 01-12 : 09, %d - Day of month 01-31 : 01\n",
    "# %H - Hour 00-23 : 17, %M - Minute 00-59 : 41, %S - Second 00-59 : 08, %f - Microsecond 000000-999999 : 548513\n",
    "col_ts = ['offline_timestamp', 'online_timestamp', 'end_date_time']\n",
    "for col in col_ts:\n",
    "    result.loc[:,col] = pd.to_datetime(result.loc[:,col], format='%Y-%m-%d %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new columns to check time different between cell offline timestamp (offline_timestamp) and drive end test (end_date_time)\n",
    "result.loc[:, 'time_dif'] = (result.loc[:, 'end_date_time'] - result.loc[:, 'offline_timestamp']).astype('timedelta64[s]')\n",
    "result.loc[:, 'time_dif_abs'] = (result.loc[:, 'end_date_time'] - result.loc[:, 'offline_timestamp']).astype('timedelta64[s]').abs()\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save result which is included of new 2 columns of time_dif and time_dif_abs\n",
    "result.to_csv('Desktop/python_data/result3_timedif.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new DF to store result data which is group by offline_timestamp, online_timestamp, and endtimestamp\n",
    "df1minstart=result.groupby(['offline_timestamp', 'online_timestamp', 'end_date_time'])['time_dif_abs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1minstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame.assign() = method to assign new columns to a DF, returning a new object\n",
    "#.transform() = function call func on self producing a DF with transformed values and that has the same axis length as self\n",
    "\n",
    "result=result.assign(min=df1minstart.transform(min))\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check min time different of min and time_dif_abs\n",
    "result = result[result.loc[:, 'min'] == result.loc[:, 'time_dif_abs']]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save result with header to result3.csv to the result directory\n",
    "result.to_csv('Desktop/python_data/result3_final.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
